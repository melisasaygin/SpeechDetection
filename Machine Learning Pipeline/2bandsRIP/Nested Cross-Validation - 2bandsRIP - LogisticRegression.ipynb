{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3e66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the needed libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, recall_score, f1_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b842b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_diff_mean</th>\n",
       "      <th>A_exp_dur_sd</th>\n",
       "      <th>A_exp_diff_mean</th>\n",
       "      <th>exp_dur_sd</th>\n",
       "      <th>duty_cycle_mean</th>\n",
       "      <th>A_RRV_RMSSD</th>\n",
       "      <th>RRV_RMSSD</th>\n",
       "      <th>ie_ratio_mean</th>\n",
       "      <th>A_duty_cycle_mean</th>\n",
       "      <th>insp_flow_sd</th>\n",
       "      <th>Task_Label</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.164364</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.156604</td>\n",
       "      <td>0.492097</td>\n",
       "      <td>404.771735</td>\n",
       "      <td>376.386712</td>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>1.445912e+06</td>\n",
       "      <td>12.0a</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.201451</td>\n",
       "      <td>0.174588</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.152211</td>\n",
       "      <td>0.486992</td>\n",
       "      <td>392.384431</td>\n",
       "      <td>351.137516</td>\n",
       "      <td>0.950939</td>\n",
       "      <td>0.485336</td>\n",
       "      <td>1.034691e+06</td>\n",
       "      <td>12.0b</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.251690</td>\n",
       "      <td>0.236719</td>\n",
       "      <td>0.213642</td>\n",
       "      <td>0.476697</td>\n",
       "      <td>459.428807</td>\n",
       "      <td>457.608476</td>\n",
       "      <td>0.913378</td>\n",
       "      <td>0.482721</td>\n",
       "      <td>1.890795e+06</td>\n",
       "      <td>12.0c</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285156</td>\n",
       "      <td>0.197705</td>\n",
       "      <td>0.266276</td>\n",
       "      <td>0.213173</td>\n",
       "      <td>0.477750</td>\n",
       "      <td>450.569753</td>\n",
       "      <td>439.827676</td>\n",
       "      <td>0.918119</td>\n",
       "      <td>0.484587</td>\n",
       "      <td>1.316481e+06</td>\n",
       "      <td>12.0d</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.193377</td>\n",
       "      <td>0.108073</td>\n",
       "      <td>0.213828</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>516.192869</td>\n",
       "      <td>457.645154</td>\n",
       "      <td>0.936229</td>\n",
       "      <td>0.488034</td>\n",
       "      <td>9.634884e+05</td>\n",
       "      <td>12.0e</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.209238</td>\n",
       "      <td>0.218316</td>\n",
       "      <td>0.200555</td>\n",
       "      <td>0.490259</td>\n",
       "      <td>357.971103</td>\n",
       "      <td>334.175635</td>\n",
       "      <td>0.967894</td>\n",
       "      <td>0.488741</td>\n",
       "      <td>2.209139e+06</td>\n",
       "      <td>85</td>\n",
       "      <td>98586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>0.921387</td>\n",
       "      <td>0.731201</td>\n",
       "      <td>0.941894</td>\n",
       "      <td>0.725393</td>\n",
       "      <td>0.401725</td>\n",
       "      <td>1042.040237</td>\n",
       "      <td>1209.145284</td>\n",
       "      <td>0.933997</td>\n",
       "      <td>0.431877</td>\n",
       "      <td>1.280213e+07</td>\n",
       "      <td>87</td>\n",
       "      <td>98586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>0.106337</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.117894</td>\n",
       "      <td>0.496388</td>\n",
       "      <td>153.331025</td>\n",
       "      <td>185.358320</td>\n",
       "      <td>0.987026</td>\n",
       "      <td>0.494804</td>\n",
       "      <td>2.990174e+06</td>\n",
       "      <td>89</td>\n",
       "      <td>98586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>2.145182</td>\n",
       "      <td>1.115591</td>\n",
       "      <td>1.260045</td>\n",
       "      <td>1.447558</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>2387.940073</td>\n",
       "      <td>3053.223554</td>\n",
       "      <td>0.748645</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>1.441962e+07</td>\n",
       "      <td>91</td>\n",
       "      <td>98586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>0.123535</td>\n",
       "      <td>0.163306</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.150457</td>\n",
       "      <td>0.480523</td>\n",
       "      <td>174.011428</td>\n",
       "      <td>159.999651</td>\n",
       "      <td>0.926293</td>\n",
       "      <td>0.483312</td>\n",
       "      <td>2.040140e+06</td>\n",
       "      <td>93</td>\n",
       "      <td>98586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2904 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      exp_diff_mean  A_exp_dur_sd  A_exp_diff_mean  exp_dur_sd  \\\n",
       "0          0.127790      0.164364         0.117188    0.156604   \n",
       "1          0.201451      0.174588         0.241071    0.152211   \n",
       "2          0.199219      0.251690         0.236719    0.213642   \n",
       "3          0.285156      0.197705         0.266276    0.213173   \n",
       "4          0.159375      0.193377         0.108073    0.213828   \n",
       "...             ...           ...              ...         ...   \n",
       "2899       0.203125      0.209238         0.218316    0.200555   \n",
       "2900       0.921387      0.731201         0.941894    0.725393   \n",
       "2901       0.106337      0.115003         0.101562    0.117894   \n",
       "2902       2.145182      1.115591         1.260045    1.447558   \n",
       "2903       0.123535      0.163306         0.132812    0.150457   \n",
       "\n",
       "      duty_cycle_mean  A_RRV_RMSSD    RRV_RMSSD  ie_ratio_mean  \\\n",
       "0            0.492097   404.771735   376.386712       0.971761   \n",
       "1            0.486992   392.384431   351.137516       0.950939   \n",
       "2            0.476697   459.428807   457.608476       0.913378   \n",
       "3            0.477750   450.569753   439.827676       0.918119   \n",
       "4            0.481671   516.192869   457.645154       0.936229   \n",
       "...               ...          ...          ...            ...   \n",
       "2899         0.490259   357.971103   334.175635       0.967894   \n",
       "2900         0.401725  1042.040237  1209.145284       0.933997   \n",
       "2901         0.496388   153.331025   185.358320       0.987026   \n",
       "2902         0.412197  2387.940073  3053.223554       0.748645   \n",
       "2903         0.480523   174.011428   159.999651       0.926293   \n",
       "\n",
       "      A_duty_cycle_mean  insp_flow_sd Task_Label  Participant  Classification  \n",
       "0              0.492399  1.445912e+06      12.0a        10785               0  \n",
       "1              0.485336  1.034691e+06      12.0b        10785               0  \n",
       "2              0.482721  1.890795e+06      12.0c        10785               0  \n",
       "3              0.484587  1.316481e+06      12.0d        10785               0  \n",
       "4              0.488034  9.634884e+05      12.0e        10785               0  \n",
       "...                 ...           ...        ...          ...             ...  \n",
       "2899           0.488741  2.209139e+06         85        98586               0  \n",
       "2900           0.431877  1.280213e+07         87        98586               1  \n",
       "2901           0.494804  2.990174e+06         89        98586               0  \n",
       "2902           0.360902  1.441962e+07         91        98586               1  \n",
       "2903           0.483312  2.040140e+06         93        98586               0  \n",
       "\n",
       "[2904 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the data we will use in the machine learning pipeline, with the top ten features of the method\n",
    "df = pd.read_excel('hexoskin_2bands_training_set_10_final.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897f50b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.27790200e-01, 1.64364500e-01, 1.17187500e-01, ...,\n",
       "         9.71761000e-01, 4.92398700e-01, 1.44591181e+06],\n",
       "        [2.01450900e-01, 1.74588400e-01, 2.41071400e-01, ...,\n",
       "         9.50939100e-01, 4.85336100e-01, 1.03469140e+06],\n",
       "        [1.99218800e-01, 2.51689700e-01, 2.36718800e-01, ...,\n",
       "         9.13377900e-01, 4.82720700e-01, 1.89079541e+06],\n",
       "        ...,\n",
       "        [1.06336800e-01, 1.15003100e-01, 1.01562500e-01, ...,\n",
       "         9.87025600e-01, 4.94804200e-01, 2.99017395e+06],\n",
       "        [2.14518230e+00, 1.11559080e+00, 1.26004460e+00, ...,\n",
       "         7.48644500e-01, 3.60902200e-01, 1.44196160e+07],\n",
       "        [1.23535200e-01, 1.63306400e-01, 1.32812500e-01, ...,\n",
       "         9.26293000e-01, 4.83311700e-01, 2.04013979e+06]]),\n",
       " 'target': array([0, 0, 0, ..., 0, 1, 0]),\n",
       " 'feature_names': ['exp_diff_mean',\n",
       "  'A_exp_dur_sd',\n",
       "  'A_exp_diff_mean',\n",
       "  'exp_dur_sd',\n",
       "  'duty_cycle_mean',\n",
       "  'A_RRV_RMSSD',\n",
       "  'RRV_RMSSD',\n",
       "  'ie_ratio_mean',\n",
       "  'A_duty_cycle_mean',\n",
       "  'insp_flow_sd'],\n",
       " 'participants': array([10785, 10785, 10785, ..., 98586, 98586, 98586]),\n",
       " 'task': array(['12.0a', '12.0b', '12.0c', ..., 89, 91, 93], dtype=object)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the features from the DataFrame\n",
    "features = df.drop(columns=['Classification', 'Participant', 'Task_Label'])\n",
    "\n",
    "# extracting the Classification (0/1) and participants from the dataframe\n",
    "target = df['Classification'].values\n",
    "participants = df['Participant'].values\n",
    "task = df['Task_Label'].values\n",
    "\n",
    "# extracting the feature names\n",
    "feature_names = features.columns.tolist()\n",
    "\n",
    "# converting the features, target, participants to numpy arrays\n",
    "features_array = features.values\n",
    "target_array = target\n",
    "\n",
    "# creating the dictionary with the needed format to enter into the nested cross-validation\n",
    "data_dict = {\n",
    "    'data': features_array,\n",
    "    'target': target_array,\n",
    "    'feature_names': feature_names,\n",
    "    'participants': participants,\n",
    "    'task': task\n",
    "}\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd8e90a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86292136        nan 0.37069081 0.63635393 0.86680018        nan\n",
      " 0.37069081 0.63635393 0.8671523         nan 0.37069081 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86680143        nan 0.37209926 0.63635393 0.86785652        nan\n",
      " 0.372452   0.63635393 0.86574447        nan 0.37069081 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87454915        nan 0.36364607 0.36364607 0.87631406        nan\n",
      " 0.36364607 0.36364607 0.87842735        nan 0.36364607 0.36364607]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86856075        nan 0.37492486 0.63635393 0.86820801        nan\n",
      " 0.37492486 0.63635393 0.86715043        nan 0.37492486 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86539111        nan 0.3706964  0.63635393 0.86715168        nan\n",
      " 0.3706964  0.63635393 0.86715105        nan 0.3706964  0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86785901        nan 0.37492486 0.63635393 0.86750441        nan\n",
      " 0.37492486 0.63635393 0.86856137        nan 0.37492486 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86644807        nan 0.37245572 0.57860745 0.8689141         nan\n",
      " 0.37245572 0.57860745 0.86750441        nan 0.37245572 0.57860745]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86891534        nan 0.37422125 0.63635393 0.87349281        nan\n",
      " 0.37351703 0.63635393 0.87349281        nan 0.37351703 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86715105        nan 0.37139938 0.63635393 0.86926559        nan\n",
      " 0.37034305 0.63635393 0.86926497        nan 0.37210671 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86714981        nan 0.37069578 0.63635393 0.86715105        nan\n",
      " 0.37069578 0.63635393 0.86820739        nan 0.37069578 0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8667977         nan 0.37633269 0.63635393 0.8675013         nan\n",
      " 0.37633269 0.63635393 0.86644435        nan 0.37210734 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87772561        nan 0.37422001 0.57860745 0.87878319        nan\n",
      " 0.37316181 0.57860745 0.88195283        nan 0.37140125 0.57860745]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8699723         nan 0.36999093 0.63635393 0.87631282        nan\n",
      " 0.36999093 0.63635393 0.87173349        nan 0.36999093 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87137889        nan 0.37140125 0.63635393 0.87314194        nan\n",
      " 0.37140125 0.63635393 0.8727892         nan 0.37140125 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86997168        nan 0.37034367 0.63635393 0.8720856         nan\n",
      " 0.36999093 0.63635393 0.87278983        nan 0.37034367 0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8682105         nan 0.36999093 0.63635393 0.87032566        nan\n",
      " 0.36999093 0.63635393 0.87032504        nan 0.36999093 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86539173        nan 0.36999093 0.63635393 0.86962081        nan\n",
      " 0.36999093 0.63635393 0.86856261        nan 0.36999093 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86785901        nan 0.37316181 0.63635393 0.87314566        nan\n",
      " 0.37316181 0.63635393 0.874202          nan 0.37316181 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.865039          nan 0.37316305 0.63635393 0.86785776        nan\n",
      " 0.37210671 0.63635393 0.86962143        nan 0.37316305 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86855888        nan 0.37034305 0.63635393 0.86714919        nan\n",
      " 0.3724551  0.63635393 0.86750193        nan 0.37139876 0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86855951        nan 0.3735133  0.63635393 0.87032131        nan\n",
      " 0.37175274 0.63635393 0.87208498        nan 0.37175274 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86644683        nan 0.37175274 0.63635393 0.87102988        nan\n",
      " 0.37175274 0.63635393 0.8699723         nan 0.37562598 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86715105        nan 0.37245634 0.63635393 0.86715105        nan\n",
      " 0.37245634 0.63635393 0.8678559         nan 0.37210423 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86855826        nan 0.36928671 0.63635393 0.86820615        nan\n",
      " 0.36928671 0.63635393 0.87138324        nan 0.36928671 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87173287        nan 0.36964006 0.63635393 0.86714919        nan\n",
      " 0.36964006 0.63635393 0.87208498        nan 0.36964006 0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86397707        nan 0.3699928  0.63635393 0.86961957        nan\n",
      " 0.3699928  0.63635393 0.86891596        nan 0.3699928  0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86891596        nan 0.37175646 0.63635393 0.87032504        nan\n",
      " 0.37175646 0.63635393 0.86644931        nan 0.37175646 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86151166        nan 0.37140435 0.63635393 0.86327471        nan\n",
      " 0.37140435 0.63635393 0.86151415        nan 0.37140435 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86679832        nan 0.37175522 0.63635393 0.86820677        nan\n",
      " 0.37175522 0.63635393 0.86750193        nan 0.37175522 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87173473        nan 0.36964068 0.57966379 0.87490561        nan\n",
      " 0.37351392 0.57966379 0.87244206        nan 0.36964068 0.57966379]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86715478        nan 0.37069764 0.63635393 0.86856696        nan\n",
      " 0.37069764 0.63635393 0.86786335        nan 0.37069764 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86574757        nan 0.37069764 0.63635393 0.86222645        nan\n",
      " 0.37069764 0.63635393 0.86328403        nan 0.37069764 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86962205        nan 0.36963944 0.63635393 0.87208746        nan\n",
      " 0.36963944 0.63635393 0.87138634        nan 0.36963944 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8671554         nan 0.37140373 0.63635393 0.86503962        nan\n",
      " 0.37352013 0.63635393 0.86222272        nan 0.3689346  0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87068025        nan 0.37246193 0.63635393 0.86892093        nan\n",
      " 0.37246193 0.63635393 0.87279479        nan 0.37246193 0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86645242        nan 0.3717546  0.63635393 0.86539608        nan\n",
      " 0.3717546  0.63635393 0.86680639        nan 0.3717546  0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86856634        nan 0.3721092  0.63635393 0.86645118        nan\n",
      " 0.3721092  0.63635393 0.86680329        nan 0.37351765 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87032938        nan 0.37175709 0.57966379 0.86927305        nan\n",
      " 0.37175709 0.57966379 0.86997665        nan 0.37175709 0.57966379]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86292694        nan 0.371051   0.58944035 0.86363241        nan\n",
      " 0.37140373 0.58944035 0.86363303        nan 0.36928733 0.58944035]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86504148        nan 0.371051   0.63635393 0.86716037        nan\n",
      " 0.371051   0.63635393 0.86892031        nan 0.371051   0.63635393]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86821671        nan 0.37069826 0.63635393 0.87244703        nan\n",
      " 0.371051   0.63635393 0.87103858        nan 0.37069826 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86504521        nan 0.3699928  0.63635393 0.87103858        nan\n",
      " 0.3699928  0.63635393 0.87033311        nan 0.3699928  0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87420883        nan 0.3689346  0.63635393 0.87737971        nan\n",
      " 0.3689346  0.63635393 0.87597126        nan 0.37246193 0.63635393]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nested_accuracy_scores:    [0.92424242 0.84848485 0.62121212 0.89393939 0.96969697 0.89393939\n",
      " 0.92424242 0.81818182 0.92424242 0.92424242 0.93939394 0.63636364\n",
      " 0.8030303  0.81818182 0.81818182 0.92424242 0.98484848 0.75757576\n",
      " 0.92424242 0.86363636 0.89393939 0.93939394 0.8030303  0.8030303\n",
      " 0.81818182 0.89393939 0.93939394 0.98484848 0.78787879 0.72727273\n",
      " 0.87878788 0.98484848 0.83333333 0.98484848 0.71212121 0.93939394\n",
      " 0.89393939 0.84848485 0.96969697 0.87878788 0.75757576 0.8030303\n",
      " 0.75757576 0.90909091]\n",
      "mean score:            0.8626\n",
      "nested_precision_scores:    [0.93230174 0.87762238 0.71192905 0.89525499 0.97107438 0.89962333\n",
      " 0.92611833 0.8161157  0.92398198 0.92611833 0.94805195 0.6684492\n",
      " 0.82815249 0.85858586 0.82727273 0.92532151 0.98520085 0.75636364\n",
      " 0.92398198 0.87024087 0.91788856 0.94466403 0.85479682 0.84958678\n",
      " 0.83787879 0.90909091 0.94008264 0.98520085 0.78661616 0.72477522\n",
      " 0.8885851  0.98545455 0.84808947 0.98520085 0.72913666 0.94805195\n",
      " 0.89962333 0.85353535 0.97107438 0.88063241 0.75636364 0.80505543\n",
      " 0.80130348 0.90909091]\n",
      "mean score:            0.8746\n",
      "nested_recall_scores:    [0.92424242 0.84848485 0.62121212 0.89393939 0.96969697 0.89393939\n",
      " 0.92424242 0.81818182 0.92424242 0.92424242 0.93939394 0.63636364\n",
      " 0.8030303  0.81818182 0.81818182 0.92424242 0.98484848 0.75757576\n",
      " 0.92424242 0.86363636 0.89393939 0.93939394 0.8030303  0.8030303\n",
      " 0.81818182 0.89393939 0.93939394 0.98484848 0.78787879 0.72727273\n",
      " 0.87878788 0.98484848 0.83333333 0.98484848 0.71212121 0.93939394\n",
      " 0.89393939 0.84848485 0.96969697 0.87878788 0.75757576 0.8030303\n",
      " 0.75757576 0.90909091]\n",
      "mean score:            0.8626\n",
      "nested_f1_scores:    [0.91377058 0.81522956 0.62112514 0.88640275 0.96663296 0.87927881\n",
      " 0.91570881 0.79979778 0.91739675 0.91570881 0.93653846 0.62781955\n",
      " 0.7974026  0.77083333 0.78478261 0.91885911 0.98347935 0.71304348\n",
      " 0.91739675 0.85620915 0.89090909 0.93181818 0.80078941 0.74727541\n",
      " 0.81196581 0.87617261 0.93326593 0.98347935 0.75555556 0.66741321\n",
      " 0.87307692 0.98377182 0.82660616 0.98347935 0.70050155 0.93653846\n",
      " 0.87927881 0.82539683 0.96663296 0.86363636 0.71304348 0.78903369\n",
      " 0.75396086 0.89989889]\n",
      "mean score:            0.8484\n",
      "nested_roc_auc_scores:    [1.         0.99603175 0.5952381  0.93452381 1.         0.9890873\n",
      " 0.99603175 0.91071429 0.96230159 0.98710317 0.95535714 0.65575397\n",
      " 0.90178571 0.94146825 0.90178571 0.98511905 1.         0.90079365\n",
      " 0.96031746 0.92063492 0.91071429 0.99305556 0.97718254 0.7827381\n",
      " 0.89484127 0.98412698 0.9890873  1.         0.89285714 0.89980159\n",
      " 0.97123016 1.         0.90178571 1.         0.84623016 0.99107143\n",
      " 0.97619048 0.9484127  0.99404762 0.95833333 0.89583333 0.88888889\n",
      " 0.92162698 0.97916667]\n",
      "mean score:            0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86786335        nan 0.37281467 0.63635393 0.86751372        nan\n",
      " 0.37281467 0.63635393 0.86786397        nan 0.37281467 0.63635393]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#running the nested cross-validation for the 2bandsRIP method using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X = data_dict['data']\n",
    "Y = data_dict['target']\n",
    "groups = data_dict['participants']\n",
    "\n",
    "# setting up the parameter grid: the combinations of these will be tried out for ever outer loop's inner loop\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : (1, 4, 20),\n",
    "    'solver' : ['liblinear','lbfgs']\n",
    "}\n",
    "\n",
    "\n",
    "lrc = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "\n",
    "# defining the techniques to use for the inner and outer loops\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "outer_cv = logo.split(X, Y, groups)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_score': make_scorer(f1_score, average='macro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, needs_proba=True, average='weighted')\n",
    "}\n",
    "\n",
    "# performing nested cross-validation\n",
    "clf = GridSearchCV(estimator=lrc, param_grid=param_grid, cv=inner_cv)\n",
    "cv_dic = cross_validate(clf, X, Y, cv=outer_cv, scoring=scoring, return_estimator=True, return_train_score=False)\n",
    "mean_acc_score = cv_dic['test_accuracy'].mean()\n",
    "mean_prec_score = cv_dic['test_precision'].mean()\n",
    "mean_rec_score = cv_dic['test_recall'].mean()\n",
    "mean_f1_score = cv_dic['test_f1_score'].mean()\n",
    "mean_roc_auc = cv_dic['test_roc_auc'].mean()  # Mean ROC AUC score\n",
    "\n",
    "\n",
    "print('nested_accuracy_scores:   ', cv_dic['test_accuracy'])\n",
    "print('mean score:            {0:.4f}'.format(mean_acc_score))\n",
    "\n",
    "print('nested_precision_scores:   ', cv_dic['test_precision'])\n",
    "print('mean score:            {0:.4f}'.format(mean_prec_score))\n",
    "\n",
    "print('nested_recall_scores:   ', cv_dic['test_recall'])\n",
    "print('mean score:            {0:.4f}'.format(mean_rec_score))\n",
    "\n",
    "print('nested_f1_scores:   ', cv_dic['test_f1_score'])\n",
    "print('mean score:            {0:.4f}'.format(mean_f1_score))\n",
    "\n",
    "print('nested_roc_auc_scores:   ', cv_dic['test_roc_auc'])\n",
    "print('mean score:            {0:.4f}'.format(mean_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998c50d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Sensitivity: 0.7917\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 2:\n",
      "Sensitivity: 0.5833\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 3:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.5000\n",
      "==============================\n",
      "Fold 4:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 5:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 6:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 7:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 8:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 0.8810\n",
      "==============================\n",
      "Fold 9:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 10:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 11:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 12:\n",
      "Sensitivity: 0.6667\n",
      "Specificity: 0.6190\n",
      "==============================\n",
      "Fold 13:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.7619\n",
      "==============================\n",
      "Fold 14:\n",
      "Sensitivity: 0.5000\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 15:\n",
      "Sensitivity: 0.5833\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 16:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9286\n",
      "==============================\n",
      "Fold 17:\n",
      "Sensitivity: 0.9583\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 18:\n",
      "Sensitivity: 0.5000\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 19:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 20:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.8571\n",
      "==============================\n",
      "Fold 21:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.8333\n",
      "==============================\n",
      "Fold 22:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 23:\n",
      "Sensitivity: 0.9583\n",
      "Specificity: 0.7143\n",
      "==============================\n",
      "Fold 24:\n",
      "Sensitivity: 0.4583\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 25:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.7857\n",
      "==============================\n",
      "Fold 26:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 27:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 28:\n",
      "Sensitivity: 0.9583\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 29:\n",
      "Sensitivity: 0.5833\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 30:\n",
      "Sensitivity: 0.4167\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 31:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.8571\n",
      "==============================\n",
      "Fold 32:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 33:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.8095\n",
      "==============================\n",
      "Fold 34:\n",
      "Sensitivity: 0.9583\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 35:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 0.7143\n",
      "==============================\n",
      "Fold 36:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 37:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 38:\n",
      "Sensitivity: 0.6667\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 39:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 40:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 41:\n",
      "Sensitivity: 0.5000\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 42:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.8333\n",
      "==============================\n",
      "Fold 43:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.6905\n",
      "==============================\n",
      "Fold 44:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Average Sensitivity: 0.793560606060606\n",
      "Average Specificity: 0.902056277056277\n"
     ]
    }
   ],
   "source": [
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# iteration over the outer folds to calculate average sensitivity and specificity\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X, Y, groups)):\n",
    "    print(f\"Fold {i + 1}:\")\n",
    "\n",
    "    # getting the trained estimator for the present fold\n",
    "    estimator = cv_dic['estimator'][i]\n",
    "    \n",
    "    # predicting on the test set\n",
    "    y_pred = estimator.predict(X[test_index])\n",
    "    \n",
    "    # creating confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(Y[test_index], y_pred).ravel()\n",
    "    \n",
    "    # calculating the sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # store the sensitivity and specificity scores\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "    \n",
    "    # calculate and print the averages of the sensitivity and specificity scores previously calculated\n",
    "average_sensitivity = np.mean(sensitivity_scores)\n",
    "average_specificity = np.mean(specificity_scores)\n",
    "\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d128933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: Mean=0.8626033057851241, SD=0.09010673213162679, 95% CI=(0.835978957101464, 0.8892276544687843), Min=0.6212121212121212, Max=0.9848484848484849\n",
      "test_precision: Mean=0.8746258984901207, SD=0.08068481609444823, 95% CI=(0.85078549693125, 0.8984663000489914), Min=0.6684491978609626, Max=0.9854545454545454\n",
      "test_recall: Mean=0.8626033057851241, SD=0.09010673213162679, 95% CI=(0.835978957101464, 0.8892276544687843), Min=0.6212121212121212, Max=0.9848484848484849\n",
      "test_f1_score: Mean=0.8484299325459536, SD=0.09783960226672235, 95% CI=(0.8195207087377412, 0.8773391563541659), Min=0.6211251435132032, Max=0.9837718219818048\n",
      "test_roc_auc: Mean=0.9338924963924963, SD=0.08413126387239243, 95% CI=(0.9090337533047599, 0.9587512394802327), Min=0.5952380952380953, Max=1.0\n",
      "sensitivity_scores: Mean=0.793560606060606, SD=0.16098718026748857, 95% CI=(0.7459928081875273, 0.8411284039336846), Min=0.4166666666666667, Max=1.0\n",
      "specificity_scores: Mean=0.902056277056277, SD=0.11484450750997083, 95% CI=(0.8681225171693676, 0.9359900369431864), Min=0.5, Max=1.0\n"
     ]
    }
   ],
   "source": [
    "#print all performance scores that might be of interest\n",
    "import scipy.stats\n",
    "\n",
    "def calculate_stats(data):\n",
    "    mean = np.mean(data)\n",
    "    sd = np.std(data, ddof=1)  # using sample standard deviation (N-1)\n",
    "    ci = scipy.stats.norm.interval(0.95, loc=mean, scale=sd/np.sqrt(len(data)))\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    return mean, sd, ci, min_val, max_val\n",
    "\n",
    "keys = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1_score', 'test_roc_auc', 'sensitivity_scores', 'specificity_scores']\n",
    "\n",
    "for key in keys:\n",
    "    if key in cv_dic:\n",
    "        data = cv_dic[key]\n",
    "    elif key == 'sensitivity_scores':\n",
    "        data = sensitivity_scores\n",
    "    elif key == 'specificity_scores':\n",
    "        data = specificity_scores\n",
    "\n",
    "    stats = calculate_stats(data)\n",
    "    print(f\"{key}: Mean={stats[0]}, SD={stats[1]}, 95% CI={stats[2]}, Min={stats[3]}, Max={stats[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67cb9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 2 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 3 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 4 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 5 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 6 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 7 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 8 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 9 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 10 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 11 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 12 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 13 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 14 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 15 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 16 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 17 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 18 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 19 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 20 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 21 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 22 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 23 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 24 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 25 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 26 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 27 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 28 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 29 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 30 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 31 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 32 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 33 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 34 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 35 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 36 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 37 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 38 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 39 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 40 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 41 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 42 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 43 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 44 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# IF this is the best-performing nested CV for the method: print best hyperparameters for each outer loop\n",
    "for fold_idx, estimator in enumerate(cv_dic['estimator']):\n",
    "    print(f'Fold {fold_idx + 1} - Best hyperparameters: {estimator.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f53f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter: C - Most frequent value: 4 (Count: 21)\n",
      "Hyperparameter: penalty - Most frequent value: l1 (Count: 44)\n",
      "Hyperparameter: solver - Most frequent value: liblinear (Count: 44)\n"
     ]
    }
   ],
   "source": [
    "# IF this is the best-performing nested CV for the method: print mode of hyperparameters\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# initialize a dictionary to contain all hyperparameters and their values across loops\n",
    "hyperparameters = defaultdict(list)\n",
    "\n",
    "# extracting hyperparameters of each outer loop\n",
    "for estimator in cv_dic['estimator']:\n",
    "    for param, value in estimator.best_params_.items():\n",
    "        hyperparameters[param].append(value)\n",
    "\n",
    "# count the most frequent value for each hyperparameter\n",
    "for param, values in hyperparameters.items():\n",
    "    most_common_value, count = Counter(values).most_common(1)[0]  # Get the most frequent value\n",
    "    print(f'Hyperparameter: {param} - Most frequent value: {most_common_value} (Count: {count})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
