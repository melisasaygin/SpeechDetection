{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3e66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the needed libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, recall_score, f1_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b842b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImP_exp_diff_mean</th>\n",
       "      <th>ImP_exp_dur_sd</th>\n",
       "      <th>ImP_RRV_RMSSD</th>\n",
       "      <th>ImP_insp_flow_sd</th>\n",
       "      <th>ImP_ie_ratio_sd</th>\n",
       "      <th>ImP_duty_cycle_mean</th>\n",
       "      <th>ImP_insp_amp_sd</th>\n",
       "      <th>ImP_exp_amp_sd</th>\n",
       "      <th>ImP_RSP_Symmetry_PeakTrough</th>\n",
       "      <th>ImP_ie_ratio_mean</th>\n",
       "      <th>Task_Label</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118857</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>382.434308</td>\n",
       "      <td>15663.415593</td>\n",
       "      <td>0.048638</td>\n",
       "      <td>0.489158</td>\n",
       "      <td>50985.092943</td>\n",
       "      <td>46774.304708</td>\n",
       "      <td>0.517348</td>\n",
       "      <td>0.958792</td>\n",
       "      <td>12.0a</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225143</td>\n",
       "      <td>0.173505</td>\n",
       "      <td>390.361005</td>\n",
       "      <td>20811.126431</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.485452</td>\n",
       "      <td>30734.204708</td>\n",
       "      <td>31615.925634</td>\n",
       "      <td>0.527694</td>\n",
       "      <td>0.945842</td>\n",
       "      <td>12.0b</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.222699</td>\n",
       "      <td>434.669530</td>\n",
       "      <td>16277.918645</td>\n",
       "      <td>0.050025</td>\n",
       "      <td>0.476758</td>\n",
       "      <td>31615.118946</td>\n",
       "      <td>26435.238020</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.912526</td>\n",
       "      <td>12.0c</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250667</td>\n",
       "      <td>0.190379</td>\n",
       "      <td>403.425334</td>\n",
       "      <td>15714.039237</td>\n",
       "      <td>0.071244</td>\n",
       "      <td>0.483507</td>\n",
       "      <td>29114.145601</td>\n",
       "      <td>25312.370962</td>\n",
       "      <td>0.530733</td>\n",
       "      <td>0.938632</td>\n",
       "      <td>12.0d</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.174310</td>\n",
       "      <td>483.103302</td>\n",
       "      <td>6162.134521</td>\n",
       "      <td>0.124387</td>\n",
       "      <td>0.481444</td>\n",
       "      <td>43005.468164</td>\n",
       "      <td>28574.347285</td>\n",
       "      <td>0.527149</td>\n",
       "      <td>0.936589</td>\n",
       "      <td>12.0e</td>\n",
       "      <td>10785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.274684</td>\n",
       "      <td>318.223192</td>\n",
       "      <td>3850.325373</td>\n",
       "      <td>0.265283</td>\n",
       "      <td>0.489451</td>\n",
       "      <td>8019.865362</td>\n",
       "      <td>14865.886766</td>\n",
       "      <td>0.523436</td>\n",
       "      <td>0.988002</td>\n",
       "      <td>85</td>\n",
       "      <td>98586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.764264</td>\n",
       "      <td>1236.868088</td>\n",
       "      <td>72599.234334</td>\n",
       "      <td>0.375168</td>\n",
       "      <td>0.427189</td>\n",
       "      <td>121971.615000</td>\n",
       "      <td>102499.398673</td>\n",
       "      <td>0.511816</td>\n",
       "      <td>0.809380</td>\n",
       "      <td>87</td>\n",
       "      <td>98586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>0.119556</td>\n",
       "      <td>0.122849</td>\n",
       "      <td>159.285907</td>\n",
       "      <td>4549.907724</td>\n",
       "      <td>0.082769</td>\n",
       "      <td>0.499069</td>\n",
       "      <td>6323.609559</td>\n",
       "      <td>12526.615103</td>\n",
       "      <td>0.543171</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>89</td>\n",
       "      <td>98586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>1.567500</td>\n",
       "      <td>0.980966</td>\n",
       "      <td>2899.130116</td>\n",
       "      <td>21555.712739</td>\n",
       "      <td>0.546540</td>\n",
       "      <td>0.482030</td>\n",
       "      <td>47869.716992</td>\n",
       "      <td>51080.627080</td>\n",
       "      <td>0.472444</td>\n",
       "      <td>1.070194</td>\n",
       "      <td>91</td>\n",
       "      <td>98586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.161568</td>\n",
       "      <td>319.002015</td>\n",
       "      <td>8914.484143</td>\n",
       "      <td>0.111208</td>\n",
       "      <td>0.483198</td>\n",
       "      <td>18589.573486</td>\n",
       "      <td>16991.057481</td>\n",
       "      <td>0.520749</td>\n",
       "      <td>0.941271</td>\n",
       "      <td>93</td>\n",
       "      <td>98586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2574 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ImP_exp_diff_mean  ImP_exp_dur_sd  ImP_RRV_RMSSD  ImP_insp_flow_sd  \\\n",
       "0              0.118857        0.171499     382.434308      15663.415593   \n",
       "1              0.225143        0.173505     390.361005      20811.126431   \n",
       "2              0.236000        0.222699     434.669530      16277.918645   \n",
       "3              0.250667        0.190379     403.425334      15714.039237   \n",
       "4              0.140800        0.174310     483.103302       6162.134521   \n",
       "...                 ...             ...            ...               ...   \n",
       "2569           0.240000        0.274684     318.223192       3850.325373   \n",
       "2570           0.708000        0.764264    1236.868088      72599.234334   \n",
       "2571           0.119556        0.122849     159.285907       4549.907724   \n",
       "2572           1.567500        0.980966    2899.130116      21555.712739   \n",
       "2573           0.216500        0.161568     319.002015       8914.484143   \n",
       "\n",
       "      ImP_ie_ratio_sd  ImP_duty_cycle_mean  ImP_insp_amp_sd  ImP_exp_amp_sd  \\\n",
       "0            0.048638             0.489158     50985.092943    46774.304708   \n",
       "1            0.069124             0.485452     30734.204708    31615.925634   \n",
       "2            0.050025             0.476758     31615.118946    26435.238020   \n",
       "3            0.071244             0.483507     29114.145601    25312.370962   \n",
       "4            0.124387             0.481444     43005.468164    28574.347285   \n",
       "...               ...                  ...              ...             ...   \n",
       "2569         0.265283             0.489451      8019.865362    14865.886766   \n",
       "2570         0.375168             0.427189    121971.615000   102499.398673   \n",
       "2571         0.082769             0.499069      6323.609559    12526.615103   \n",
       "2572         0.546540             0.482030     47869.716992    51080.627080   \n",
       "2573         0.111208             0.483198     18589.573486    16991.057481   \n",
       "\n",
       "      ImP_RSP_Symmetry_PeakTrough  ImP_ie_ratio_mean Task_Label  Participant  \\\n",
       "0                        0.517348           0.958792      12.0a        10785   \n",
       "1                        0.527694           0.945842      12.0b        10785   \n",
       "2                        0.520548           0.912526      12.0c        10785   \n",
       "3                        0.530733           0.938632      12.0d        10785   \n",
       "4                        0.527149           0.936589      12.0e        10785   \n",
       "...                           ...                ...        ...          ...   \n",
       "2569                     0.523436           0.988002         85        98586   \n",
       "2570                     0.511816           0.809380         87        98586   \n",
       "2571                     0.543171           0.999821         89        98586   \n",
       "2572                     0.472444           1.070194         91        98586   \n",
       "2573                     0.520749           0.941271         93        98586   \n",
       "\n",
       "      Classification  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "2569               0  \n",
       "2570               1  \n",
       "2571               0  \n",
       "2572               1  \n",
       "2573               0  \n",
       "\n",
       "[2574 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the data we will use in the machine learning pipeline, with the top ten features of the method\n",
    "df = pd.read_excel('5fs_impedance_training_set_10_final.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897f50b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.18857100e-01, 1.71499300e-01, 3.82434308e+02, ...,\n",
       "         4.67743047e+04, 5.17347900e-01, 9.58791500e-01],\n",
       "        [2.25142900e-01, 1.73505000e-01, 3.90361005e+02, ...,\n",
       "         3.16159256e+04, 5.27694200e-01, 9.45842000e-01],\n",
       "        [2.36000000e-01, 2.22698600e-01, 4.34669530e+02, ...,\n",
       "         2.64352380e+04, 5.20547800e-01, 9.12525700e-01],\n",
       "        ...,\n",
       "        [1.19555600e-01, 1.22848900e-01, 1.59285907e+02, ...,\n",
       "         1.25266151e+04, 5.43171200e-01, 9.99821100e-01],\n",
       "        [1.56750000e+00, 9.80965500e-01, 2.89913012e+03, ...,\n",
       "         5.10806271e+04, 4.72444400e-01, 1.07019450e+00],\n",
       "        [2.16500000e-01, 1.61567600e-01, 3.19002015e+02, ...,\n",
       "         1.69910575e+04, 5.20748900e-01, 9.41270500e-01]]),\n",
       " 'target': array([0, 0, 0, ..., 0, 1, 0]),\n",
       " 'feature_names': ['ImP_exp_diff_mean',\n",
       "  'ImP_exp_dur_sd',\n",
       "  'ImP_RRV_RMSSD',\n",
       "  'ImP_insp_flow_sd',\n",
       "  'ImP_ie_ratio_sd',\n",
       "  'ImP_duty_cycle_mean',\n",
       "  'ImP_insp_amp_sd',\n",
       "  'ImP_exp_amp_sd',\n",
       "  'ImP_RSP_Symmetry_PeakTrough',\n",
       "  'ImP_ie_ratio_mean'],\n",
       " 'participants': array([10785, 10785, 10785, ..., 98586, 98586, 98586]),\n",
       " 'task': array(['12.0a', '12.0b', '12.0c', ..., 89, 91, 93], dtype=object)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the features from the DataFrame\n",
    "features = df.drop(columns=['Classification', 'Participant', 'Task_Label'])\n",
    "\n",
    "# extracting the Classification (0/1) and participants from the dataframe\n",
    "target = df['Classification'].values\n",
    "participants = df['Participant'].values\n",
    "task = df['Task_Label'].values\n",
    "\n",
    "# extracting the feature names\n",
    "feature_names = features.columns.tolist()\n",
    "\n",
    "# converting the features, target, participants to numpy arrays\n",
    "features_array = features.values\n",
    "target_array = target\n",
    "\n",
    "# creating the dictionary with the needed format to enter into the nested cross-validation\n",
    "data_dict = {\n",
    "    'data': features_array,\n",
    "    'target': target_array,\n",
    "    'feature_names': feature_names,\n",
    "    'participants': participants,\n",
    "    'task': task\n",
    "}\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd8e90a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89314439        nan 0.85964963 0.61997519 0.89314121        nan\n",
      " 0.86204086 0.61997519 0.89234519        nan 0.86522811 0.61997519]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8935412         nan 0.86682571 0.62925702 0.893142          nan\n",
      " 0.8660281  0.62925702 0.89433802        nan 0.8664273  0.62925702]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89633482        nan 0.86602651 0.62566182 0.89553642        nan\n",
      " 0.86921933 0.62566182 0.89553642        nan 0.86921933 0.62566182]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8943404         nan 0.8648305  0.56898156 0.89274439        nan\n",
      " 0.8652289  0.56898156 0.8927436         nan 0.8652289  0.56898156]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8943404         nan 0.86842093 0.56977917 0.8935412         nan\n",
      " 0.86842093 0.56977917 0.89473722        nan 0.87081137 0.56977917]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89354279        nan 0.86842093 0.56738952 0.89393882        nan\n",
      " 0.86842172 0.56738952 0.893542          nan 0.87041216 0.56738952]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89314518        nan 0.86483129 0.62407933 0.89394279        nan\n",
      " 0.86602572 0.62407933 0.89314518        nan 0.8640313  0.62407933]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.893542          nan 0.86522572 0.63272817 0.89234439        nan\n",
      " 0.86442891 0.63272817 0.89274439        nan 0.86442971 0.63272817]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89433961        nan 0.86921456 0.57655844 0.89234758        nan\n",
      " 0.86642253 0.57655844 0.893942          nan 0.86642253 0.57655844]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89992207        nan 0.86841377 0.62886418 0.90071968        nan\n",
      " 0.86881218 0.62886418 0.9007165         nan 0.8704058  0.62886418]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89593482        nan 0.86722332 0.62567375 0.89513881        nan\n",
      " 0.86841854 0.62567375 0.89593562        nan 0.86762173 0.62567375]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89115077        nan 0.8628337  0.61678635 0.89314359        nan\n",
      " 0.86203688 0.61678635 0.89234678        nan 0.86442971 0.61678635]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.893942          nan 0.86522652 0.61798316 0.8943404         nan\n",
      " 0.86602413 0.61798316 0.89553642        nan 0.86602413 0.61798316]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.893542          nan 0.8660281  0.57296721 0.89553642        nan\n",
      " 0.86682492 0.57296721 0.89513881        nan 0.86722412 0.57296721]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89354279        nan 0.86403448 0.6256658  0.893942          nan\n",
      " 0.86523368 0.6256658  0.893942          nan 0.86523368 0.6256658 ]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89514119        nan 0.86722412 0.57177438 0.8947396         nan\n",
      " 0.8664281  0.57177438 0.89633403        nan 0.87161454 0.57177438]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89554198        nan 0.86683048 0.57137438 0.89673561        nan\n",
      " 0.86842411 0.57137438 0.89554039        nan 0.86962171 0.57137438]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89434676        nan 0.87201851 0.62636082 0.89514278        nan\n",
      " 0.87122011 0.62636082 0.89514278        nan 0.87122011 0.62636082]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89514358        nan 0.86683446 0.57057916 0.89434438        nan\n",
      " 0.86603685 0.57057916 0.89514119        nan 0.86603685 0.57057916]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89753402        nan 0.86882251 0.57496561 0.89912685        nan\n",
      " 0.87001853 0.57496561 0.90112047        nan 0.87001853 0.57496561]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89673959        nan 0.86722968 0.5717712  0.8971372         nan\n",
      " 0.86762809 0.5717712  0.89713799        nan 0.86802729 0.5717712 ]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89394995        nan 0.86762809 0.5721712  0.89474517        nan\n",
      " 0.86762809 0.5721712  0.89474517        nan 0.86842649 0.5721712 ]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89315155        nan 0.86683128 0.57057359 0.89434597        nan\n",
      " 0.86603287 0.57057359 0.89434517        nan 0.86882729 0.57057359]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89036191        nan 0.86285119 0.57456243 0.89235314        nan\n",
      " 0.86165359 0.57456243 0.89155474        nan 0.86285119 0.57456243]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89195712        nan 0.86484004 0.62326502 0.89315234        nan\n",
      " 0.86484004 0.62326502 0.89394915        nan 0.86484004 0.62326502]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89554516        nan 0.87162011 0.57735207 0.89873401        nan\n",
      " 0.87082329 0.57735207 0.89793481        nan 0.87162011 0.57735207]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89235314        nan 0.86802809 0.5637983  0.89274996        nan\n",
      " 0.86603606 0.5637983  0.89434358        nan 0.86762968 0.5637983 ]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89275314        nan 0.86683048 0.57097677 0.89314996        nan\n",
      " 0.86683048 0.57097677 0.89275075        nan 0.86683048 0.57097677]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89354995        nan 0.86722968 0.57137518 0.89394836        nan\n",
      " 0.86523368 0.57137518 0.89394677        nan 0.86722968 0.57137518]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89753799        nan 0.87082011 0.56858156 0.8979364         nan\n",
      " 0.87121852 0.56858156 0.89554516        nan 0.87121852 0.56858156]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89395074        nan 0.86882729 0.57017837 0.89195712        nan\n",
      " 0.86882729 0.57017837 0.89355075        nan 0.86842888 0.57017837]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89395074        nan 0.86523924 0.57177279 0.89315234        nan\n",
      " 0.86563844 0.57177279 0.89474676        nan 0.86723207 0.57177279]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89155633        nan 0.8688241  0.58054409 0.89235394        nan\n",
      " 0.86722968 0.58054409 0.89275155        nan 0.8684249  0.58054409]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.88996111        nan 0.86762809 0.62766499 0.89075872        nan\n",
      " 0.8684257  0.62766499 0.89115554        nan 0.86882649 0.62766499]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89275234        nan 0.8680265  0.68382597 0.89195394        nan\n",
      " 0.8688241  0.68382597 0.89474517        nan 0.87041773 0.68382597]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89793481        nan 0.8716217  0.62646023 0.89873162        nan\n",
      " 0.8716217  0.62646023 0.89833242        nan 0.8716217  0.62646023]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89115951        nan 0.8696241  0.63204905 0.89156031        nan\n",
      " 0.86603844 0.63204905 0.89195792        nan 0.8696241  0.63204905]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89554596        nan 0.8676273  0.68195323 0.89594516        nan\n",
      " 0.86802729 0.68195323 0.89594357        nan 0.86722889 0.68195323]\n",
      "  warnings.warn(\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/melisa/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.89155633        nan 0.86324562 0.57137756 0.89235553        nan\n",
      " 0.86244881 0.57137756 0.89275393        nan 0.86244881 0.57137756]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nested_accuracy_scores:    [0.92424242 0.87878788 0.8030303  0.89393939 0.87878788 0.92424242\n",
      " 0.92424242 0.93939394 0.90909091 0.77272727 0.89393939 0.98484848\n",
      " 0.90909091 0.90909091 0.95454545 0.86363636 0.87878788 0.87878788\n",
      " 0.90909091 0.6969697  0.81818182 0.89393939 0.92424242 0.95454545\n",
      " 0.92424242 0.78787879 0.93939394 0.90909091 0.87878788 0.81818182\n",
      " 0.90909091 0.87878788 0.92424242 1.         0.93939394 0.74242424\n",
      " 0.93939394 0.84848485 0.95454545]\n",
      "mean score:            0.8901\n",
      "nested_precision_scores:    [0.93230174 0.89818182 0.80595875 0.89962333 0.89818182 0.92611833\n",
      " 0.92532151 0.94008264 0.91223776 0.78861306 0.91788856 0.98545455\n",
      " 0.91223776 0.90909091 0.95757576 0.86694493 0.8885851  0.8885851\n",
      " 0.92045455 0.71868687 0.82255245 0.90909091 0.92981093 0.95459141\n",
      " 0.92532151 0.78512397 0.94213287 0.90909091 0.88234266 0.83787879\n",
      " 0.91223776 0.88699495 0.92611833 1.         0.93939394 0.75887486\n",
      " 0.94008264 0.86767677 0.95757576]\n",
      "mean score:            0.8969\n",
      "nested_recall_scores:    [0.92424242 0.87878788 0.8030303  0.89393939 0.87878788 0.92424242\n",
      " 0.92424242 0.93939394 0.90909091 0.77272727 0.89393939 0.98484848\n",
      " 0.90909091 0.90909091 0.95454545 0.86363636 0.87878788 0.87878788\n",
      " 0.90909091 0.6969697  0.81818182 0.89393939 0.92424242 0.95454545\n",
      " 0.92424242 0.78787879 0.93939394 0.90909091 0.87878788 0.81818182\n",
      " 0.90909091 0.87878788 0.92424242 1.         0.93939394 0.74242424\n",
      " 0.93939394 0.84848485 0.95454545]\n",
      "mean score:            0.8901\n",
      "nested_f1_scores:    [0.91377058 0.85652174 0.77003484 0.87927881 0.85652174 0.91570881\n",
      " 0.91885911 0.93326593 0.90341463 0.76355386 0.89090909 0.98377182\n",
      " 0.90341463 0.89989889 0.94942529 0.84478704 0.87307692 0.87307692\n",
      " 0.8952381  0.68660969 0.80682927 0.87617261 0.92011619 0.95043805\n",
      " 0.91885911 0.76643074 0.93560976 0.89989889 0.87121951 0.81196581\n",
      " 0.90341463 0.86031746 0.91570881 1.         0.93452381 0.7320277\n",
      " 0.93326593 0.84330484 0.94942529]\n",
      "mean score:            0.8805\n",
      "nested_roc_auc_scores:    [0.99305556 0.99900794 0.93849206 0.93849206 0.8968254  0.98214286\n",
      " 0.97519841 0.98710317 0.94742063 0.8452381  0.9890873  0.99900794\n",
      " 0.9890873  0.98511905 1.         0.93650794 0.97916667 0.93055556\n",
      " 1.         0.72619048 0.92857143 0.96130952 0.9890873  0.99503968\n",
      " 0.95634921 0.89285714 0.97519841 0.92162698 0.95734127 0.88095238\n",
      " 0.96527778 0.98115079 0.97619048 1.         0.98214286 0.85714286\n",
      " 0.96428571 0.95535714 0.99900794]\n",
      "mean score:            0.9532\n"
     ]
    }
   ],
   "source": [
    "#running the nested cross-validation for the Accelerometer method using Gradient Boosting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X = data_dict['data']\n",
    "Y = data_dict['target']\n",
    "groups = data_dict['participants']\n",
    "\n",
    "# setting up the parameter grid: the combinations of these will be tried out for ever outer loop's inner loop\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : (1, 4, 20),\n",
    "    'solver' : ['liblinear','lbfgs']\n",
    "}\n",
    "\n",
    "\n",
    "lrc = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "\n",
    "# defining the techniques to use for the inner and outer loops\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "outer_cv = logo.split(X, Y, groups)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_score': make_scorer(f1_score, average='macro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, needs_proba=True, average='weighted')\n",
    "}\n",
    "\n",
    "# performing nested cross-validation\n",
    "clf = GridSearchCV(estimator=lrc, param_grid=param_grid, cv=inner_cv)\n",
    "cv_dic = cross_validate(clf, X, Y, cv=outer_cv, scoring=scoring, return_estimator=True, return_train_score=False)\n",
    "mean_acc_score = cv_dic['test_accuracy'].mean()\n",
    "mean_prec_score = cv_dic['test_precision'].mean()\n",
    "mean_rec_score = cv_dic['test_recall'].mean()\n",
    "mean_f1_score = cv_dic['test_f1_score'].mean()\n",
    "mean_roc_auc = cv_dic['test_roc_auc'].mean()  # Mean ROC AUC score\n",
    "\n",
    "\n",
    "print('nested_accuracy_scores:   ', cv_dic['test_accuracy'])\n",
    "print('mean score:            {0:.4f}'.format(mean_acc_score))\n",
    "\n",
    "print('nested_precision_scores:   ', cv_dic['test_precision'])\n",
    "print('mean score:            {0:.4f}'.format(mean_prec_score))\n",
    "\n",
    "print('nested_recall_scores:   ', cv_dic['test_recall'])\n",
    "print('mean score:            {0:.4f}'.format(mean_rec_score))\n",
    "\n",
    "print('nested_f1_scores:   ', cv_dic['test_f1_score'])\n",
    "print('mean score:            {0:.4f}'.format(mean_f1_score))\n",
    "\n",
    "print('nested_roc_auc_scores:   ', cv_dic['test_roc_auc'])\n",
    "print('mean score:            {0:.4f}'.format(mean_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998c50d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Sensitivity: 0.7917\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 2:\n",
      "Sensitivity: 0.6667\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 3:\n",
      "Sensitivity: 0.5833\n",
      "Specificity: 0.9286\n",
      "==============================\n",
      "Fold 4:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 5:\n",
      "Sensitivity: 0.6667\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 6:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 7:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9286\n",
      "==============================\n",
      "Fold 8:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 9:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 10:\n",
      "Sensitivity: 0.7917\n",
      "Specificity: 0.7619\n",
      "==============================\n",
      "Fold 11:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.8333\n",
      "==============================\n",
      "Fold 12:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 13:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 14:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 15:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 16:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 17:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.8571\n",
      "==============================\n",
      "Fold 18:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.8571\n",
      "==============================\n",
      "Fold 19:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 20:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 0.6905\n",
      "==============================\n",
      "Fold 21:\n",
      "Sensitivity: 0.7917\n",
      "Specificity: 0.8333\n",
      "==============================\n",
      "Fold 22:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 23:\n",
      "Sensitivity: 0.9583\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 24:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 25:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9286\n",
      "==============================\n",
      "Fold 26:\n",
      "Sensitivity: 0.6667\n",
      "Specificity: 0.8571\n",
      "==============================\n",
      "Fold 27:\n",
      "Sensitivity: 0.9583\n",
      "Specificity: 0.9286\n",
      "==============================\n",
      "Fold 28:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 29:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.8810\n",
      "==============================\n",
      "Fold 30:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.7857\n",
      "==============================\n",
      "Fold 31:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9048\n",
      "==============================\n",
      "Fold 32:\n",
      "Sensitivity: 0.7083\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 33:\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 34:\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Fold 35:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.9524\n",
      "==============================\n",
      "Fold 36:\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.7381\n",
      "==============================\n",
      "Fold 37:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 0.9762\n",
      "==============================\n",
      "Fold 38:\n",
      "Sensitivity: 0.9167\n",
      "Specificity: 0.8095\n",
      "==============================\n",
      "Fold 39:\n",
      "Sensitivity: 0.8750\n",
      "Specificity: 1.0000\n",
      "==============================\n",
      "Average Sensitivity: 0.8386752136752137\n",
      "Average Specificity: 0.9194139194139194\n"
     ]
    }
   ],
   "source": [
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# iteration over the outer folds to calculate average sensitivity and specificity\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X, Y, groups)):\n",
    "    print(f\"Fold {i + 1}:\")\n",
    "\n",
    "    # getting the trained estimator for the present fold\n",
    "    estimator = cv_dic['estimator'][i]\n",
    "    \n",
    "    # predicting on the test set\n",
    "    y_pred = estimator.predict(X[test_index])\n",
    "    \n",
    "    # creating confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(Y[test_index], y_pred).ravel()\n",
    "    \n",
    "    # calculating the sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # store the sensitivity and specificity scores\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "    \n",
    "    # calculate and print the averages of the sensitivity and specificity scores previously calculated\n",
    "average_sensitivity = np.mean(sensitivity_scores)\n",
    "average_specificity = np.mean(specificity_scores)\n",
    "\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d128933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: Mean=0.8900543900543902, SD=0.0642559219590999, 95% CI=(0.8698879636014833, 0.9102208165072971), Min=0.696969696969697, Max=1.0\n",
      "test_precision: Mean=0.8968978524147891, SD=0.06049640107753749, 95% CI=(0.8779113343507846, 0.9158843704787937), Min=0.7186868686868687, Max=1.0\n",
      "test_recall: Mean=0.8900543900543902, SD=0.0642559219590999, 95% CI=(0.8698879636014833, 0.9102208165072971), Min=0.696969696969697, Max=1.0\n",
      "test_f1_score: Mean=0.8805299191536536, SD=0.0678037707394258, 95% CI=(0.8592500166301673, 0.90180982167714), Min=0.6866096866096867, Max=1.0\n",
      "test_roc_auc: Mean=0.9532458282458282, SD=0.054903333091551605, 95% CI=(0.9360146689214786, 0.9704769875701778), Min=0.7261904761904763, Max=1.0\n",
      "sensitivity_scores: Mean=0.8386752136752137, SD=0.10609163773616119, 95% CI=(0.805378839668837, 0.8719715876815903), Min=0.5833333333333334, Max=1.0\n",
      "specificity_scores: Mean=0.9194139194139194, SD=0.08131559836242101, 95% CI=(0.8938933917512134, 0.9449344470766253), Min=0.6904761904761905, Max=1.0\n"
     ]
    }
   ],
   "source": [
    "#print all performance scores that might be of interest\n",
    "import scipy.stats\n",
    "\n",
    "def calculate_stats(data):\n",
    "    mean = np.mean(data)\n",
    "    sd = np.std(data, ddof=1)  # using sample standard deviation (N-1)\n",
    "    ci = scipy.stats.norm.interval(0.95, loc=mean, scale=sd/np.sqrt(len(data)))\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    return mean, sd, ci, min_val, max_val\n",
    "\n",
    "keys = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1_score', 'test_roc_auc', 'sensitivity_scores', 'specificity_scores']\n",
    "\n",
    "for key in keys:\n",
    "    if key in cv_dic:\n",
    "        data = cv_dic[key]\n",
    "    elif key == 'sensitivity_scores':\n",
    "        data = sensitivity_scores\n",
    "    elif key == 'specificity_scores':\n",
    "        data = specificity_scores\n",
    "\n",
    "    stats = calculate_stats(data)\n",
    "    print(f\"{key}: Mean={stats[0]}, SD={stats[1]}, 95% CI={stats[2]}, Min={stats[3]}, Max={stats[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67cb9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 2 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 3 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 4 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 5 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 6 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 7 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 8 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 9 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 10 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 11 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 12 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 13 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 14 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 15 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 16 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 17 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 18 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 19 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 20 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 21 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 22 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 23 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 24 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 25 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 26 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 27 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 28 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 29 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 30 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 31 - Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 32 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 33 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 34 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 35 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 36 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 37 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 38 - Best hyperparameters: {'C': 4, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Fold 39 - Best hyperparameters: {'C': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# IF this is the best-performing nested CV for the method: print best hyperparameters for each outer loop\n",
    "for fold_idx, estimator in enumerate(cv_dic['estimator']):\n",
    "    print(f'Fold {fold_idx + 1} - Best hyperparameters: {estimator.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f53f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter: C - Most frequent value: 20 (Count: 16)\n",
      "Hyperparameter: penalty - Most frequent value: l1 (Count: 39)\n",
      "Hyperparameter: solver - Most frequent value: liblinear (Count: 39)\n"
     ]
    }
   ],
   "source": [
    "# IF this is the best-performing nested CV for the method: print mode of hyperparameters\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# initialize a dictionary to contain all hyperparameters and their values across loops\n",
    "hyperparameters = defaultdict(list)\n",
    "\n",
    "# extracting hyperparameters of each outer loop\n",
    "for estimator in cv_dic['estimator']:\n",
    "    for param, value in estimator.best_params_.items():\n",
    "        hyperparameters[param].append(value)\n",
    "\n",
    "# count the most frequent value for each hyperparameter\n",
    "for param, values in hyperparameters.items():\n",
    "    most_common_value, count = Counter(values).most_common(1)[0]  # Get the most frequent value\n",
    "    print(f'Hyperparameter: {param} - Most frequent value: {most_common_value} (Count: {count})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
